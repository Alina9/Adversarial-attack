# Аdversarial attack

## Dataset
MNIST: Рукописные цифры

## Описание метода

Аdversarial attack заключается в модификации исходного изображения таким образом, что изменения практически не заметны человеческому взгляду. При отправление полученного изображения в классификатор ошибочно классифицируется, когда исходное изображение классифицируется правильно.

Здесь приведен пример, когда изменение картинок приводит к тому, что они ошибочно начинают классифицироваться как восьмерки.
